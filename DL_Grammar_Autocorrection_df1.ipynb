{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s9EMM_Twwj7I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from transformers import DistilBertModel, DistilBertTokenizerFast\n",
        "import torch\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YelhLoTjwr6Z",
        "outputId": "bfae31e9-0ff3-441d-b624-90240b800b96"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Grammar_autocorrection_df1_new.csv')"
      ],
      "metadata": {
        "id": "m57o9eOFwurN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DistilBERT"
      ],
      "metadata": {
        "id": "7TQCdJZlEKhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ── 0) Configuration ────────────────────────────────────────────────────────\n",
        "# MODEL_DIR = 'distilbert_saved_model'\n",
        "\n",
        "# # ── 1) If already saved, just reload ────────────────────────────────────────\n",
        "# if os.path.isdir(MODEL_DIR):\n",
        "#     tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_DIR)\n",
        "#     model     = DistilBertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "#     print(f\"Loaded existing model from '{MODEL_DIR}', skipping training.\")\n",
        "\n",
        "# # ── 2) Otherwise: 5-fold CV with metrics + retrain full head ────────────────\n",
        "# else:\n",
        "#     # Prepare texts & labels\n",
        "#     texts  = df['Ungrammatical Statement'].tolist() + df['Standard English'].tolist()\n",
        "#     labels = [0]*len(df) + [1]*len(df)\n",
        "\n",
        "#     # Initialize tokenizer & pre-tokenize\n",
        "#     tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "#     encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "#     # Build Hugging Face Dataset\n",
        "#     dataset = Dataset.from_dict({\n",
        "#         'input_ids':      encodings['input_ids'],\n",
        "#         'attention_mask': encodings['attention_mask'],\n",
        "#         'labels':         labels\n",
        "#     })\n",
        "\n",
        "#     # Load model & freeze encoder layers\n",
        "#     model = DistilBertForSequenceClassification.from_pretrained(\n",
        "#         'distilbert-base-uncased',\n",
        "#         num_labels=2\n",
        "#     )\n",
        "#     for param in model.distilbert.parameters():\n",
        "#         param.requires_grad = False\n",
        "\n",
        "#     # Data collator for dynamic padding\n",
        "#     data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "#     # Metric computation function\n",
        "#     def compute_metrics(p):\n",
        "#         preds = p.predictions.argmax(-1)\n",
        "#         acc   = accuracy_score(p.label_ids, preds)\n",
        "#         prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "#             p.label_ids, preds, average='binary'\n",
        "#         )\n",
        "#         return {\n",
        "#             'accuracy':  acc,\n",
        "#             'precision': prec,\n",
        "#             'recall':    rec,\n",
        "#             'f1':        f1\n",
        "#         }\n",
        "\n",
        "#     # Prepare lists to collect per-fold metrics\n",
        "#     accuracy_scores  = []\n",
        "#     precision_scores = []\n",
        "#     recall_scores    = []\n",
        "#     f1_scores        = []\n",
        "\n",
        "#     # 5-fold CV, 1 epoch per fold for speed\n",
        "#     cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "#     for fold, (train_idx, val_idx) in enumerate(cv.split(texts, labels), start=1):\n",
        "#         print(f\"=== Fold {fold}/5 ===\")\n",
        "#         train_ds = dataset.select(train_idx)\n",
        "#         val_ds   = dataset.select(val_idx)\n",
        "\n",
        "#         training_args = TrainingArguments(\n",
        "#             output_dir=f'./cv_fold{fold}',\n",
        "#             num_train_epochs=1,\n",
        "#             per_device_train_batch_size=16,\n",
        "#             per_device_eval_batch_size=32,\n",
        "#             eval_strategy='epoch',\n",
        "#             logging_strategy='epoch',\n",
        "#             save_strategy='no',\n",
        "#             fp16=True,               # set to False if no GPU\n",
        "#             report_to=['none'],\n",
        "#             seed=42\n",
        "#         )\n",
        "\n",
        "#         trainer = Trainer(\n",
        "#             model=model,\n",
        "#             args=training_args,\n",
        "#             train_dataset=train_ds,\n",
        "#             eval_dataset=val_ds,\n",
        "#             data_collator=data_collator,\n",
        "#             compute_metrics=compute_metrics\n",
        "#         )\n",
        "\n",
        "#         trainer.train()\n",
        "#         metrics = trainer.evaluate()\n",
        "\n",
        "#         # Collect metrics\n",
        "#         accuracy_scores.append(metrics['eval_accuracy'])\n",
        "#         precision_scores.append(metrics['eval_precision'])\n",
        "#         recall_scores.append(metrics['eval_recall'])\n",
        "#         f1_scores.append(metrics['eval_f1'])\n",
        "\n",
        "#         # Print per-fold results\n",
        "#         print(f\"Fold {fold}: \"\n",
        "#               f\"Acc {metrics['eval_accuracy']:.4f}, \"\n",
        "#               f\"Prec {metrics['eval_precision']:.4f}, \"\n",
        "#               f\"Rec {metrics['eval_recall']:.4f}, \"\n",
        "#               f\"F1 {metrics['eval_f1']:.4f}\")\n",
        "\n",
        "#     # Summarize CV\n",
        "#     def report(name, vals):\n",
        "#         mean, std = np.mean(vals), np.std(vals)\n",
        "#         print(f\"{name}: {mean:.4f} ± {std:.4f}\")\n",
        "\n",
        "#     print(\"\\n=== CV summary over 5 folds ===\")\n",
        "#     report(\"Accuracy\",  accuracy_scores)\n",
        "#     report(\"Precision\", precision_scores)\n",
        "#     report(\"Recall\",    recall_scores)\n",
        "#     report(\"F1-score\",  f1_scores)\n",
        "\n",
        "#     # Retrain head on full dataset\n",
        "#     print(\"\\nRetraining classifier head on the full dataset…\")\n",
        "#     full_args = TrainingArguments(\n",
        "#         output_dir='./full_train',\n",
        "#         num_train_epochs=2,\n",
        "#         per_device_train_batch_size=16,\n",
        "#         save_strategy='no',\n",
        "#         fp16=True,\n",
        "#         report_to=['none']\n",
        "#     )\n",
        "#     trainer_full = Trainer(\n",
        "#         model=model,\n",
        "#         args=full_args,\n",
        "#         train_dataset=dataset,\n",
        "#         data_collator=data_collator,\n",
        "#         compute_metrics=compute_metrics\n",
        "#     )\n",
        "#     trainer_full.train()\n",
        "\n",
        "#     # Save the fine-tuned model & tokenizer\n",
        "#     model.save_pretrained(MODEL_DIR)\n",
        "#     tokenizer.save_pretrained(MODEL_DIR)\n",
        "#     print(f\"Saved model in '{MODEL_DIR}'\")\n"
      ],
      "metadata": {
        "id": "6BYqyHQtwzyg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1) Load your saved model & tokenizer\n",
        "# MODEL_DIR = 'distilbert_saved_model'\n",
        "# tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_DIR)\n",
        "# model     = DistilBertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "# model.eval()\n",
        "\n",
        "# # 2) Prompt the user for input\n",
        "# sentence = input(\"Enter a sentence to check (grammar):\\n> \")\n",
        "\n",
        "# # 3) Tokenize & forward pass\n",
        "# enc = tokenizer([sentence], padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
        "# with torch.no_grad():\n",
        "#     logits = model(**enc).logits\n",
        "\n",
        "# # 4) Convert to probabilities & predicted label\n",
        "# probs = torch.softmax(logits, dim=-1)[0]\n",
        "# pred  = probs.argmax().item()\n",
        "# label = \"Correct\" if pred == 1 else \"Ungrammatical\"\n",
        "# score = probs[pred].item()\n",
        "\n",
        "# # 5) Print result\n",
        "# print(f\"\\n\\\"{sentence}\\\" → {label} (confidence: {score:.2f})\")"
      ],
      "metadata": {
        "id": "yJRQg-aIN6wy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T5 Model\n"
      ],
      "metadata": {
        "id": "Ecw7gE_dyUL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pandas as pd\n",
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "# from datasets import Dataset\n",
        "# import torch\n",
        "# from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "\n",
        "# model_name = \"t5-small\"\n",
        "# model_dir = \"./t5-grammar-correction\"\n",
        "\n",
        "# # Load tokenizer and model\n",
        "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# if os.path.exists(model_dir):\n",
        "#     print(\"Saved model found. Loading the model...\")\n",
        "#     model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
        "# else:\n",
        "#     print(\"No saved model found. Training model from scratch...\")\n",
        "#     model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "#     # Prepare input and target sequences\n",
        "#     inputs = [\"fix: \" + text for text in df['Ungrammatical Statement']]\n",
        "#     targets = df['Standard English'].tolist()\n",
        "\n",
        "#     # Tokenize input and output\n",
        "#     input_encodings = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=64, return_tensors=\"pt\")\n",
        "#     target_encodings = tokenizer(targets, padding=\"max_length\", truncation=True, max_length=64, return_tensors=\"pt\")\n",
        "\n",
        "#     labels = target_encodings[\"input_ids\"]\n",
        "#     labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "#     dataset = Dataset.from_dict({\n",
        "#         'input_ids': input_encodings['input_ids'],\n",
        "#         'attention_mask': input_encodings['attention_mask'],\n",
        "#         'labels': labels\n",
        "#     })\n",
        "\n",
        "#     os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "#     training_args = TrainingArguments(\n",
        "#         output_dir=model_dir,\n",
        "#         per_device_train_batch_size=8,\n",
        "#         per_device_eval_batch_size=8,\n",
        "#         num_train_epochs=4,\n",
        "#         logging_dir=\"./logs\",\n",
        "#         save_steps=500,\n",
        "#         save_total_limit=2\n",
        "#     )\n",
        "\n",
        "#     trainer = Trainer(\n",
        "#         model=model,\n",
        "#         args=training_args,\n",
        "#         train_dataset=dataset,\n",
        "#         eval_dataset=dataset,\n",
        "#         # tokenizer=tokenizer  # Optional to keep or remove based on warning\n",
        "#     )\n",
        "\n",
        "#     trainer.train()\n",
        "#     trainer.save_model(model_dir)\n",
        "\n",
        "# # Grammar correction function\n",
        "# def correct_grammar(sentence):\n",
        "#     input_text = \"fix: \" + sentence\n",
        "#     input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=64, truncation=True)\n",
        "#     output_ids = model.generate(input_ids, max_length=64, num_beams=4, early_stopping=True)\n",
        "#     return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# # Evaluation and test code (same as before)...\n",
        "# print(\"\\nEvaluating model on the dataset...\\n\")\n",
        "\n",
        "# smoothie = SmoothingFunction().method4\n",
        "# total_bleu = 0\n",
        "# correct_count = 0\n",
        "\n",
        "# for ungram, ref in zip(df['Ungrammatical Statement'], df['Standard English']):\n",
        "#     pred = correct_grammar(ungram).strip()\n",
        "#     ref = ref.strip()\n",
        "\n",
        "#     # BLEU score\n",
        "#     ref_tokens = ref.split()\n",
        "#     pred_tokens = pred.split()\n",
        "#     bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothie)\n",
        "#     total_bleu += bleu\n",
        "\n",
        "#     # Exact match accuracy (case-insensitive)\n",
        "#     if pred.lower() == ref.lower():\n",
        "#         correct_count += 1\n",
        "\n",
        "# average_bleu = total_bleu / len(df)\n",
        "# accuracy = correct_count / len(df)\n",
        "\n",
        "# print(f\"Average BLEU score: {average_bleu:.4f}\")\n",
        "# print(f\"Exact Match Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "\n",
        "# print(f\"Average BLEU score: {average_bleu:.4f}\")\n",
        "# print(f\"Exact Match Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# # --- Test on a new example sentence ---\n",
        "# user_sentence = input(\"\\nEnter a sentence to correct grammar:\\n\")\n",
        "# corrected_sentence = correct_grammar(user_sentence)\n",
        "# print(\"Corrected:\", corrected_sentence)"
      ],
      "metadata": {
        "id": "PCrGBDDOHXD8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import torch\n",
        "\n",
        "model_name = \"t5-small\"\n",
        "model_dir = \"./t5-grammar-correction-new\"\n",
        "k_folds = 5\n",
        "num_train_epochs = 3\n",
        "max_length = 64\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "def report(name, vals):\n",
        "    mean, std = np.mean(vals), np.std(vals)\n",
        "    print(f\"{name}: {mean:.4f} ± {std:.4f}\")\n",
        "\n",
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "# Load your dataframe 'df' before this point\n",
        "# df must have columns: 'Ungrammatical Statement', 'Standard English'\n",
        "\n",
        "if os.path.exists(model_dir):\n",
        "    print(\"Saved model found. Loading the model...\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
        "\n",
        "else:\n",
        "    print(\"No saved model found. Starting training with cross-validation...\")\n",
        "\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    bleu_scores = []\n",
        "\n",
        "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "    fold_num = 1\n",
        "\n",
        "    for train_index, val_index in kf.split(df):\n",
        "        print(f\"\\n=== Fold {fold_num} ===\")\n",
        "        train_df = df.iloc[train_index].reset_index(drop=True)\n",
        "        val_df = df.iloc[val_index].reset_index(drop=True)\n",
        "\n",
        "        # Prepare datasets\n",
        "        train_inputs = [\"fix: \" + text for text in train_df['Ungrammatical Statement']]\n",
        "        train_targets = train_df['Standard English'].tolist()\n",
        "\n",
        "        val_inputs = [\"fix: \" + text for text in val_df['Ungrammatical Statement']]\n",
        "        val_targets = val_df['Standard English'].tolist()\n",
        "\n",
        "        # Tokenize train\n",
        "        train_input_encodings = tokenizer(train_inputs, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        train_target_encodings = tokenizer(train_targets, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        train_labels = train_target_encodings[\"input_ids\"]\n",
        "        train_labels[train_labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "        train_dataset = Dataset.from_dict({\n",
        "            'input_ids': train_input_encodings['input_ids'],\n",
        "            'attention_mask': train_input_encodings['attention_mask'],\n",
        "            'labels': train_labels\n",
        "        })\n",
        "\n",
        "        # Tokenize validation\n",
        "        val_input_encodings = tokenizer(val_inputs, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        val_target_encodings = tokenizer(val_targets, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        val_labels = val_target_encodings[\"input_ids\"]\n",
        "        val_labels[val_labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "        val_dataset = Dataset.from_dict({\n",
        "            'input_ids': val_input_encodings['input_ids'],\n",
        "            'attention_mask': val_input_encodings['attention_mask'],\n",
        "            'labels': val_labels\n",
        "        })\n",
        "\n",
        "        model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f\"./t5-cv-fold{fold_num}\",\n",
        "            per_device_train_batch_size=8,\n",
        "            per_device_eval_batch_size=8,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            logging_dir=\"./logs\",\n",
        "            save_steps=500,\n",
        "            save_total_limit=1,\n",
        "            # evaluation_strategy=\"epoch\",\n",
        "            # save_strategy=\"epoch\",\n",
        "            # load_best_model_at_end=True,\n",
        "            # metric_for_best_model=\"eval_loss\",\n",
        "            # greater_is_better=False,\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        predictions = []\n",
        "        references = []\n",
        "\n",
        "        for sentence in val_df['Ungrammatical Statement']:\n",
        "            input_text = \"fix: \" + sentence\n",
        "            input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(input_ids, max_length=max_length, num_beams=4, early_stopping=True)\n",
        "            pred = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "            predictions.append(pred)\n",
        "\n",
        "        references = val_df['Standard English'].str.strip().tolist()\n",
        "\n",
        "        # Calculate BLEU and exact match accuracy\n",
        "        bleu_sum = 0\n",
        "        correct_exact = 0\n",
        "        for pred, ref in zip(predictions, references):\n",
        "            pred_tokens = pred.split()\n",
        "            ref_tokens = ref.split()\n",
        "            bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothie)\n",
        "            bleu_sum += bleu\n",
        "            if pred.lower() == ref.lower():\n",
        "                correct_exact += 1\n",
        "        bleu_score = bleu_sum / len(predictions)\n",
        "        accuracy = correct_exact / len(predictions)\n",
        "\n",
        "        # Precision, Recall, F1 micro (treat exact matches as 1, else 0)\n",
        "        y_true = [1] * len(references)  # all correct labels\n",
        "        y_pred = [1 if p.lower() == r.lower() else 0 for p, r in zip(predictions, references)]\n",
        "\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            y_true, y_pred, average='micro'\n",
        "        )\n",
        "\n",
        "        print(f\"Fold {fold_num}: BLEU={bleu_score:.4f}, Accuracy={accuracy:.4f}, \"\n",
        "              f\"Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "        bleu_scores.append(bleu_score)\n",
        "\n",
        "        fold_num += 1\n",
        "\n",
        "    print(\"\\n=== Cross-validation summary ===\")\n",
        "    report(\"BLEU\", bleu_scores)\n",
        "    report(\"Accuracy\", accuracy_scores)\n",
        "    report(\"Precision\", precision_scores)\n",
        "    report(\"Recall\", recall_scores)\n",
        "    report(\"F1-score\", f1_scores)\n",
        "\n",
        "    # Final training on full dataset\n",
        "    print(\"\\nTraining on full dataset for final model...\")\n",
        "    inputs = [\"fix: \" + text for text in df['Ungrammatical Statement']]\n",
        "    targets = df['Standard English'].tolist()\n",
        "\n",
        "    input_encodings = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "    target_encodings = tokenizer(targets, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "\n",
        "    labels = target_encodings[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    full_dataset = Dataset.from_dict({\n",
        "        'input_ids': input_encodings['input_ids'],\n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': labels\n",
        "    })\n",
        "\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_dir,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        logging_dir=\"./logs\",\n",
        "        save_steps=500,\n",
        "        save_total_limit=2,\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=full_dataset,\n",
        "        eval_dataset=full_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model(model_dir)\n",
        "\n",
        "# Grammar correction function using final trained or loaded model\n",
        "def correct_grammar(sentence):\n",
        "    input_text = \"fix: \" + sentence\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
        "    output_ids = model.generate(input_ids, max_length=max_length, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# User input for correction\n",
        "user_sentence = input(\"\\nEnter a sentence to correct grammar:\\n\")\n",
        "corrected_sentence = correct_grammar(user_sentence)\n",
        "print(\"Corrected:\", corrected_sentence)\n"
      ],
      "metadata": {
        "id": "DCRp2yKr01pn",
        "outputId": "1bc165e9-8f58-4fc9-ef03-385daa232592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No saved model found. Starting training with cross-validation...\n",
            "\n",
            "=== Fold 1 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='606' max='606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [606/606 44:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.633000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: BLEU=0.6675, Accuracy=0.3540, Precision=0.3540, Recall=0.3540, F1=0.3540\n",
            "\n",
            "=== Fold 2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='606' max='606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [606/606 44:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.597300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: BLEU=0.6658, Accuracy=0.3069, Precision=0.3069, Recall=0.3069, F1=0.3069\n",
            "\n",
            "=== Fold 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='606' max='606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [606/606 44:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.617700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: BLEU=0.6688, Accuracy=0.3589, Precision=0.3589, Recall=0.3589, F1=0.3589\n",
            "\n",
            "=== Fold 4 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='606' max='606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [606/606 43:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.603100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4: BLEU=0.6783, Accuracy=0.3598, Precision=0.3598, Recall=0.3598, F1=0.3598\n",
            "\n",
            "=== Fold 5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='606' max='606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [606/606 44:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.587700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5: BLEU=0.6624, Accuracy=0.3499, Precision=0.3499, Recall=0.3499, F1=0.3499\n",
            "\n",
            "=== Cross-validation summary ===\n",
            "BLEU: 0.6686 ± 0.0053\n",
            "Accuracy: 0.3459 ± 0.0198\n",
            "Precision: 0.3459 ± 0.0198\n",
            "Recall: 0.3459 ± 0.0198\n",
            "F1-score: 0.3459 ± 0.0198\n",
            "\n",
            "Training on full dataset for final model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 54:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.611800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter a sentence to correct grammar:\n",
            "she are running late\n",
            "Corrected: she is running late\n"
          ]
        }
      ]
    }
  ]
}