{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s9EMM_Twwj7I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from transformers import DistilBertModel, DistilBertTokenizerFast\n",
        "import torch\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YelhLoTjwr6Z",
        "outputId": "88e6cb19-0972-47b6-e9c3-02ed2c343542"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Grammar_autocorrection_df1_new.csv')"
      ],
      "metadata": {
        "id": "m57o9eOFwurN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DistilBERT"
      ],
      "metadata": {
        "id": "7TQCdJZlEKhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ── 0) Configuration ────────────────────────────────────────────────────────\n",
        "MODEL_DIR = 'distilbert_saved_model'\n",
        "\n",
        "# ── 1) If already saved, just reload ────────────────────────────────────────\n",
        "if os.path.isdir(MODEL_DIR):\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_DIR)\n",
        "    model     = DistilBertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "    print(f\"Loaded existing model from '{MODEL_DIR}', skipping training.\")\n",
        "\n",
        "# ── 2) Otherwise: 5-fold CV with metrics + retrain full head ────────────────\n",
        "else:\n",
        "    # Prepare texts & labels\n",
        "    texts  = df['Ungrammatical Statement'].tolist() + df['Standard English'].tolist()\n",
        "    labels = [0]*len(df) + [1]*len(df)\n",
        "\n",
        "    # Initialize tokenizer & pre-tokenize\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # Build Hugging Face Dataset\n",
        "    dataset = Dataset.from_dict({\n",
        "        'input_ids':      encodings['input_ids'],\n",
        "        'attention_mask': encodings['attention_mask'],\n",
        "        'labels':         labels\n",
        "    })\n",
        "\n",
        "    # Load model & freeze encoder layers\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased',\n",
        "        num_labels=2\n",
        "    )\n",
        "    for param in model.distilbert.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Data collator for dynamic padding\n",
        "    data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "    # Metric computation function\n",
        "    def compute_metrics(p):\n",
        "        preds = p.predictions.argmax(-1)\n",
        "        acc   = accuracy_score(p.label_ids, preds)\n",
        "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "            p.label_ids, preds, average='binary'\n",
        "        )\n",
        "        return {\n",
        "            'accuracy':  acc,\n",
        "            'precision': prec,\n",
        "            'recall':    rec,\n",
        "            'f1':        f1\n",
        "        }\n",
        "\n",
        "    # Prepare lists to collect per-fold metrics\n",
        "    accuracy_scores  = []\n",
        "    precision_scores = []\n",
        "    recall_scores    = []\n",
        "    f1_scores        = []\n",
        "\n",
        "    # 5-fold CV, 1 epoch per fold for speed\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(texts, labels), start=1):\n",
        "        print(f\"=== Fold {fold}/5 ===\")\n",
        "        train_ds = dataset.select(train_idx)\n",
        "        val_ds   = dataset.select(val_idx)\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f'./cv_fold{fold}',\n",
        "            num_train_epochs=1,\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=32,\n",
        "            eval_strategy='epoch',\n",
        "            logging_strategy='epoch',\n",
        "            save_strategy='no',\n",
        "            fp16=True,               # set to False if no GPU\n",
        "            report_to=['none'],\n",
        "            seed=42\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_ds,\n",
        "            eval_dataset=val_ds,\n",
        "            data_collator=data_collator,\n",
        "            compute_metrics=compute_metrics\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "        metrics = trainer.evaluate()\n",
        "\n",
        "        # Collect metrics\n",
        "        accuracy_scores.append(metrics['eval_accuracy'])\n",
        "        precision_scores.append(metrics['eval_precision'])\n",
        "        recall_scores.append(metrics['eval_recall'])\n",
        "        f1_scores.append(metrics['eval_f1'])\n",
        "\n",
        "        # Print per-fold results\n",
        "        print(f\"Fold {fold}: \"\n",
        "              f\"Acc {metrics['eval_accuracy']:.4f}, \"\n",
        "              f\"Prec {metrics['eval_precision']:.4f}, \"\n",
        "              f\"Rec {metrics['eval_recall']:.4f}, \"\n",
        "              f\"F1 {metrics['eval_f1']:.4f}\")\n",
        "\n",
        "    # Summarize CV\n",
        "    def report(name, vals):\n",
        "        mean, std = np.mean(vals), np.std(vals)\n",
        "        print(f\"{name}: {mean:.4f} ± {std:.4f}\")\n",
        "\n",
        "    print(\"\\n=== CV summary over 5 folds ===\")\n",
        "    report(\"Accuracy\",  accuracy_scores)\n",
        "    report(\"Precision\", precision_scores)\n",
        "    report(\"Recall\",    recall_scores)\n",
        "    report(\"F1-score\",  f1_scores)\n",
        "\n",
        "    # Retrain head on full dataset\n",
        "    print(\"\\nRetraining classifier head on the full dataset…\")\n",
        "    full_args = TrainingArguments(\n",
        "        output_dir='./full_train',\n",
        "        num_train_epochs=2,\n",
        "        per_device_train_batch_size=16,\n",
        "        save_strategy='no',\n",
        "        fp16=True,\n",
        "        report_to=['none']\n",
        "    )\n",
        "    trainer_full = Trainer(\n",
        "        model=model,\n",
        "        args=full_args,\n",
        "        train_dataset=dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "    trainer_full.train()\n",
        "\n",
        "    # Save the fine-tuned model & tokenizer\n",
        "    model.save_pretrained(MODEL_DIR)\n",
        "    tokenizer.save_pretrained(MODEL_DIR)\n",
        "    print(f\"Saved model in '{MODEL_DIR}'\")\n"
      ],
      "metadata": {
        "id": "6BYqyHQtwzyg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Load your saved model & tokenizer\n",
        "MODEL_DIR = 'distilbert_saved_model'\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_DIR)\n",
        "model     = DistilBertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "model.eval()\n",
        "\n",
        "# 2) Prompt the user for input\n",
        "sentence = input(\"Enter a sentence to check (grammar):\\n> \")\n",
        "\n",
        "# 3) Tokenize & forward pass\n",
        "enc = tokenizer([sentence], padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
        "with torch.no_grad():\n",
        "    logits = model(**enc).logits\n",
        "\n",
        "# 4) Convert to probabilities & predicted label\n",
        "probs = torch.softmax(logits, dim=-1)[0]\n",
        "pred  = probs.argmax().item()\n",
        "label = \"Correct\" if pred == 1 else \"Ungrammatical\"\n",
        "score = probs[pred].item()\n",
        "\n",
        "# 5) Print result\n",
        "print(f\"\\n\\\"{sentence}\\\" → {label} (confidence: {score:.2f})\")"
      ],
      "metadata": {
        "id": "yJRQg-aIN6wy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    T5Tokenizer, T5ForConditionalGeneration,\n",
        "    Trainer, TrainingArguments,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "MODEL_DIR = 't5_saved_model'\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "# 0. Load model if already saved\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "if os.path.isdir(MODEL_DIR):\n",
        "    tokenizer = T5Tokenizer.from_pretrained(MODEL_DIR)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)\n",
        "    print(f\"Loaded existing model from '{MODEL_DIR}', skipping training.\")\n",
        "\n",
        "else:\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 1. Prepare data\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    texts = df['Ungrammatical Statement'].tolist() + df['Standard English'].tolist()\n",
        "    class_labels = ['ungrammatical'] * len(df) + ['standard'] * len(df)\n",
        "\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "    input_texts = [f\"classify: {t}\" for t in texts]\n",
        "    label_texts = class_labels\n",
        "\n",
        "    encodings = tokenizer(input_texts, padding=\"max_length\", truncation=True, max_length=64, return_tensors=\"pt\")\n",
        "    targets = tokenizer(label_texts, padding=\"max_length\", truncation=True, max_length=5, return_tensors=\"pt\")\n",
        "\n",
        "    labels = targets[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    dataset = Dataset.from_dict({\n",
        "        'input_ids': encodings['input_ids'],\n",
        "        'attention_mask': encodings['attention_mask'],\n",
        "        'labels': labels\n",
        "    })\n",
        "\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 2. Metrics\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    def compute_metrics(p):\n",
        "        # Unpack logits from predictions\n",
        "        preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "        pred_ids = np.argmax(preds, axis=-1)\n",
        "\n",
        "        decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "        decoded_labels = tokenizer.batch_decode(\n",
        "            np.where(p.label_ids != -100, p.label_ids, tokenizer.pad_token_id),\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        preds_bin = [1 if pred.strip() == 'standard' else 0 for pred in decoded_preds]\n",
        "        labels_bin = [1 if label.strip() == 'standard' else 0 for label in decoded_labels]\n",
        "\n",
        "        acc = accuracy_score(labels_bin, preds_bin)\n",
        "        prec, rec, f1, _ = precision_recall_fscore_support(labels_bin, preds_bin, average='binary')\n",
        "        return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
        "\n",
        "\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 3. 5-Fold CV\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    accuracy_scores, precision_scores, recall_scores, f1_scores = [], [], [], []\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(input_texts, class_labels), start=1):\n",
        "        print(f\"=== Fold {fold}/5 ===\")\n",
        "        train_ds = dataset.select(train_idx)\n",
        "        val_ds = dataset.select(val_idx)\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f'./cv_fold{fold}',\n",
        "            num_train_epochs=1,\n",
        "            per_device_train_batch_size=8,\n",
        "            per_device_eval_batch_size=16,\n",
        "            save_strategy='no',\n",
        "            report_to=['none'],\n",
        "            eval_steps=500,               # Optional: manually trigger eval every 500 steps\n",
        "            logging_steps=500,\n",
        "            fp16=torch.cuda.is_available()  # Only if you're using GPU\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_ds,\n",
        "            eval_dataset=val_ds,\n",
        "            data_collator=data_collator,\n",
        "            compute_metrics=compute_metrics\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "        metrics = trainer.evaluate()\n",
        "\n",
        "        accuracy_scores.append(metrics['eval_accuracy'])\n",
        "        precision_scores.append(metrics['eval_precision'])\n",
        "        recall_scores.append(metrics['eval_recall'])\n",
        "        f1_scores.append(metrics['eval_f1'])\n",
        "\n",
        "        print(f\"Fold {fold}: Acc {metrics['eval_accuracy']:.4f}, \"\n",
        "              f\"Prec {metrics['eval_precision']:.4f}, Rec {metrics['eval_recall']:.4f}, \"\n",
        "              f\"F1 {metrics['eval_f1']:.4f}\")\n",
        "\n",
        "    def report(name, vals):\n",
        "        mean, std = np.mean(vals), np.std(vals)\n",
        "        print(f\"{name}: {mean:.4f} ± {std:.4f}\")\n",
        "\n",
        "    print(\"\\n=== CV summary over 5 folds ===\")\n",
        "    report(\"Accuracy\", accuracy_scores)\n",
        "    report(\"Precision\", precision_scores)\n",
        "    report(\"Recall\", recall_scores)\n",
        "    report(\"F1-score\", f1_scores)\n",
        "\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 4. Retrain on Full Dataset\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    print(\"\\nRetraining classifier head on the full dataset…\")\n",
        "\n",
        "    full_args = TrainingArguments(\n",
        "        output_dir='./full_train',\n",
        "        num_train_epochs=2,\n",
        "        per_device_train_batch_size=8,\n",
        "        save_strategy='no',\n",
        "        report_to=['none'],\n",
        "        fp16=torch.cuda.is_available()\n",
        "    )\n",
        "\n",
        "    trainer_full = Trainer(\n",
        "        model=model,\n",
        "        args=full_args,\n",
        "        train_dataset=dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer_full.train()\n",
        "\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 5. Save final model\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    model.save_pretrained(MODEL_DIR)\n",
        "    tokenizer.save_pretrained(MODEL_DIR)\n",
        "    print(f\"Saved model in '{MODEL_DIR}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bd0jStqYHiJ_",
        "outputId": "48030c3b-1e33-46d0-d4d0-b8027826767a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Fold 1/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [404/404 18:01, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [51/51 01:15]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: Acc 0.5000, Prec 0.0000, Rec 0.0000, F1 0.0000\n",
            "=== Fold 2/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [404/404 17:41, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [51/51 01:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: Acc 0.5006, Prec 0.0000, Rec 0.0000, F1 0.0000\n",
            "=== Fold 3/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [404/404 17:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [51/51 01:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: Acc 0.5006, Prec 0.0000, Rec 0.0000, F1 0.0000\n",
            "=== Fold 4/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [404/404 17:42, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [51/51 01:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4: Acc 0.4994, Prec 0.0000, Rec 0.0000, F1 0.0000\n",
            "=== Fold 5/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [404/404 17:17, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [51/51 01:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5: Acc 0.4994, Prec 0.0000, Rec 0.0000, F1 0.0000\n",
            "\n",
            "=== CV summary over 5 folds ===\n",
            "Accuracy: 0.5000 ± 0.0006\n",
            "Precision: 0.0000 ± 0.0000\n",
            "Recall: 0.0000 ± 0.0000\n",
            "F1-score: 0.0000 ± 0.0000\n",
            "\n",
            "Retraining classifier head on the full dataset…\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1010' max='1010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1010/1010 43:50, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.229400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.214600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model in 't5_saved_model'\n"
          ]
        }
      ]
    }
  ]
}