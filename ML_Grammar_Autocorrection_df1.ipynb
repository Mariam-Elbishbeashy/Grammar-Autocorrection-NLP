{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqHC7AOG92b2",
        "outputId": "0b111eea-1806-4200-e7a1-b2b15c0bf434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import datasets\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.base import clone\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne0AyBl8-Z1N",
        "outputId": "6da8f0a5-ffaa-47bb-bad5-e04beb23964a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Grammar_autocorrection_df1_new.csv')"
      ],
      "metadata": {
        "id": "XXrmN-9y-cUk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "gDJdvByZDn41",
        "outputId": "bdc59e6a-627b-4cda-9c0e-50cb128a3fba"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Error Type             Ungrammatical Statement  \\\n",
              "0  verb tense errors        i goes to the store everyday   \n",
              "1  verb tense errors  they was playing soccer last night   \n",
              "2  verb tense errors     she have completed her homework   \n",
              "3  verb tense errors           he do not know the answer   \n",
              "4  verb tense errors            the sun rise in the east   \n",
              "\n",
              "                      Standard English  Ungrammatical Length  Standard Length  \\\n",
              "0           i go to the store everyday                    29               27   \n",
              "1  they were playing soccer last night                    35               36   \n",
              "2       she has completed her homework                    32               31   \n",
              "3          he does not know the answer                    25               27   \n",
              "4            the sun rises in the east                    25               26   \n",
              "\n",
              "                             Tokenized Ungrammatical  \\\n",
              "0    ['i', 'goes', 'to', 'the', 'store', 'everyday']   \n",
              "1  ['they', 'was', 'playing', 'soccer', 'last', '...   \n",
              "2    ['she', 'have', 'completed', 'her', 'homework']   \n",
              "3       ['he', 'do', 'not', 'know', 'the', 'answer']   \n",
              "4        ['the', 'sun', 'rise', 'in', 'the', 'east']   \n",
              "\n",
              "                                  Tokenized Standard  \\\n",
              "0      ['i', 'go', 'to', 'the', 'store', 'everyday']   \n",
              "1  ['they', 'were', 'playing', 'soccer', 'last', ...   \n",
              "2     ['she', 'has', 'completed', 'her', 'homework']   \n",
              "3     ['he', 'does', 'not', 'know', 'the', 'answer']   \n",
              "4       ['the', 'sun', 'rises', 'in', 'the', 'east']   \n",
              "\n",
              "                                   POS_Ungrammatical  \\\n",
              "0  [('i', 'NN'), ('goes', 'VBZ'), ('to', 'TO'), (...   \n",
              "1  [('they', 'PRP'), ('was', 'VBD'), ('playing', ...   \n",
              "2  [('she', 'PRP'), ('have', 'VBP'), ('completed'...   \n",
              "3  [('he', 'PRP'), ('do', 'VBZ'), ('not', 'RB'), ...   \n",
              "4  [('the', 'DT'), ('sun', 'NN'), ('rise', 'NN'),...   \n",
              "\n",
              "                                        POS_Standard  \\\n",
              "0  [('i', 'NN'), ('go', 'VBP'), ('to', 'TO'), ('t...   \n",
              "1  [('they', 'PRP'), ('were', 'VBD'), ('playing',...   \n",
              "2  [('she', 'PRP'), ('has', 'VBZ'), ('completed',...   \n",
              "3  [('he', 'PRP'), ('does', 'VBZ'), ('not', 'RB')...   \n",
              "4  [('the', 'DT'), ('sun', 'NN'), ('rises', 'VBZ'...   \n",
              "\n",
              "                                      POS_W2V_Ungram  ...  \\\n",
              "0  [-0.09392828  0.01467511 -0.11880406 -0.019369...  ...   \n",
              "1  [-0.08057409 -0.064899   -0.22793531 -0.064086...  ...   \n",
              "2  [-0.16420007 -0.03099914 -0.17860003 -0.127690...  ...   \n",
              "3  [-0.20836382 -0.00077939 -0.24012117 -0.141872...  ...   \n",
              "4  [-0.1375149  -0.03588668 -0.17903697  0.039538...  ...   \n",
              "\n",
              "                                          W2V_Ungram  \\\n",
              "0  [-0.26300946  0.39695683  0.13605912  0.053938...   \n",
              "1  [-0.31353074  0.4317571   0.14008799  0.045958...   \n",
              "2  [-2.67656505e-01  3.97760749e-01  1.48411125e-...   \n",
              "3  [-0.31522754  0.4564127   0.18422635  0.063359...   \n",
              "4  [-0.31895906  0.41791686  0.10688009  0.039075...   \n",
              "\n",
              "                                        W2V_Standard  \\\n",
              "0  [-0.26916853  0.40635803  0.14320455  0.059786...   \n",
              "1  [-0.2976561   0.4338199   0.14537303  0.054469...   \n",
              "2  [-0.28929004  0.39424703  0.13514736  0.038457...   \n",
              "3  [-0.30345047  0.43326005  0.16985984  0.060665...   \n",
              "4  [-0.27703145  0.36579168  0.09558997  0.032692...   \n",
              "\n",
              "                               Bigrams_Ungrammatical  \\\n",
              "0  ['i goes', 'goes to', 'to the', 'the store', '...   \n",
              "1  ['they was', 'was playing', 'playing soccer', ...   \n",
              "2  ['she have', 'have completed', 'completed her'...   \n",
              "3  ['he do', 'do not', 'not know', 'know the', 't...   \n",
              "4  ['the sun', 'sun rise', 'rise in', 'in the', '...   \n",
              "\n",
              "                                    Bigrams_Standard  \\\n",
              "0  ['i go', 'go to', 'to the', 'the store', 'stor...   \n",
              "1  ['they were', 'were playing', 'playing soccer'...   \n",
              "2  ['she has', 'has completed', 'completed her', ...   \n",
              "3  ['he does', 'does not', 'not know', 'know the'...   \n",
              "4  ['the sun', 'sun rises', 'rises in', 'in the',...   \n",
              "\n",
              "                              Trigrams_Ungrammatical  \\\n",
              "0  ['i goes to', 'goes to the', 'to the store', '...   \n",
              "1  ['they was playing', 'was playing soccer', 'pl...   \n",
              "2  ['she have completed', 'have completed her', '...   \n",
              "3  ['he do not', 'do not know', 'not know the', '...   \n",
              "4  ['the sun rise', 'sun rise in', 'rise in the',...   \n",
              "\n",
              "                                   Trigrams_Standard  \\\n",
              "0  ['i go to', 'go to the', 'to the store', 'the ...   \n",
              "1  ['they were playing', 'were playing soccer', '...   \n",
              "2  ['she has completed', 'has completed her', 'co...   \n",
              "3  ['he does not', 'does not know', 'not know the...   \n",
              "4  ['the sun rises', 'sun rises in', 'rises in th...   \n",
              "\n",
              "                           W2V_Bigrams_Ungrammatical  \\\n",
              "0  [-1.4865453e-02  1.1285488e-02  2.3132097e-02 ...   \n",
              "1  [-9.9777804e-05 -2.6923325e-04 -1.0527767e-03 ...   \n",
              "2  [-0.01038111 -0.00510946  0.00610128 -0.000997...   \n",
              "3  [ 0.01418456  0.00413721  0.00204819 -0.014849...   \n",
              "4  [-0.0153868   0.00375328 -0.00371052 -0.001361...   \n",
              "\n",
              "                                W2V_Bigrams_Standard  \\\n",
              "0  [-0.01412573  0.01116349  0.02157649  0.002338...   \n",
              "1  [-0.00390252  0.00116026  0.00490098 -0.003110...   \n",
              "2  [-0.01103961 -0.00731192 -0.00655014  0.003719...   \n",
              "3  [ 0.01053579 -0.00204841  0.00280879 -0.013587...   \n",
              "4  [-0.02238916  0.00040568 -0.00079983 -0.002559...   \n",
              "\n",
              "                          W2V_Trigrams_Ungrammatical  \\\n",
              "0  [ 0.00053252 -0.00972586 -0.00517551 -0.001490...   \n",
              "1  [ 3.8320364e-03 -9.6556135e-03 -1.7034016e-03 ...   \n",
              "2  [ 0.00674664  0.00827969 -0.00871949 -0.008137...   \n",
              "3  [ 0.00571257  0.00300963  0.00256153  0.005161...   \n",
              "4  [-1.84255862e-03  6.71423273e-03  2.46263226e-...   \n",
              "\n",
              "                               W2V_Trigrams_Standard  \n",
              "0  [ 2.8302954e-03 -1.1065927e-02 -5.8973590e-03 ...  \n",
              "1  [ 0.00012496 -0.00871335 -0.00053851 -0.003852...  \n",
              "2  [-4.41420777e-03 -4.46065888e-03  1.07493391e-...  \n",
              "3  [ 7.0049549e-03  1.2993978e-02  2.4182086e-03 ...  \n",
              "4  [ 0.00578913 -0.00646036  0.00200742  0.002319...  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f76740a9-1b95-43d8-ab18-1e2080f53c7e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Error Type</th>\n",
              "      <th>Ungrammatical Statement</th>\n",
              "      <th>Standard English</th>\n",
              "      <th>Ungrammatical Length</th>\n",
              "      <th>Standard Length</th>\n",
              "      <th>Tokenized Ungrammatical</th>\n",
              "      <th>Tokenized Standard</th>\n",
              "      <th>POS_Ungrammatical</th>\n",
              "      <th>POS_Standard</th>\n",
              "      <th>POS_W2V_Ungram</th>\n",
              "      <th>...</th>\n",
              "      <th>W2V_Ungram</th>\n",
              "      <th>W2V_Standard</th>\n",
              "      <th>Bigrams_Ungrammatical</th>\n",
              "      <th>Bigrams_Standard</th>\n",
              "      <th>Trigrams_Ungrammatical</th>\n",
              "      <th>Trigrams_Standard</th>\n",
              "      <th>W2V_Bigrams_Ungrammatical</th>\n",
              "      <th>W2V_Bigrams_Standard</th>\n",
              "      <th>W2V_Trigrams_Ungrammatical</th>\n",
              "      <th>W2V_Trigrams_Standard</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>verb tense errors</td>\n",
              "      <td>i goes to the store everyday</td>\n",
              "      <td>i go to the store everyday</td>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "      <td>['i', 'goes', 'to', 'the', 'store', 'everyday']</td>\n",
              "      <td>['i', 'go', 'to', 'the', 'store', 'everyday']</td>\n",
              "      <td>[('i', 'NN'), ('goes', 'VBZ'), ('to', 'TO'), (...</td>\n",
              "      <td>[('i', 'NN'), ('go', 'VBP'), ('to', 'TO'), ('t...</td>\n",
              "      <td>[-0.09392828  0.01467511 -0.11880406 -0.019369...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.26300946  0.39695683  0.13605912  0.053938...</td>\n",
              "      <td>[-0.26916853  0.40635803  0.14320455  0.059786...</td>\n",
              "      <td>['i goes', 'goes to', 'to the', 'the store', '...</td>\n",
              "      <td>['i go', 'go to', 'to the', 'the store', 'stor...</td>\n",
              "      <td>['i goes to', 'goes to the', 'to the store', '...</td>\n",
              "      <td>['i go to', 'go to the', 'to the store', 'the ...</td>\n",
              "      <td>[-1.4865453e-02  1.1285488e-02  2.3132097e-02 ...</td>\n",
              "      <td>[-0.01412573  0.01116349  0.02157649  0.002338...</td>\n",
              "      <td>[ 0.00053252 -0.00972586 -0.00517551 -0.001490...</td>\n",
              "      <td>[ 2.8302954e-03 -1.1065927e-02 -5.8973590e-03 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>verb tense errors</td>\n",
              "      <td>they was playing soccer last night</td>\n",
              "      <td>they were playing soccer last night</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>['they', 'was', 'playing', 'soccer', 'last', '...</td>\n",
              "      <td>['they', 'were', 'playing', 'soccer', 'last', ...</td>\n",
              "      <td>[('they', 'PRP'), ('was', 'VBD'), ('playing', ...</td>\n",
              "      <td>[('they', 'PRP'), ('were', 'VBD'), ('playing',...</td>\n",
              "      <td>[-0.08057409 -0.064899   -0.22793531 -0.064086...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.31353074  0.4317571   0.14008799  0.045958...</td>\n",
              "      <td>[-0.2976561   0.4338199   0.14537303  0.054469...</td>\n",
              "      <td>['they was', 'was playing', 'playing soccer', ...</td>\n",
              "      <td>['they were', 'were playing', 'playing soccer'...</td>\n",
              "      <td>['they was playing', 'was playing soccer', 'pl...</td>\n",
              "      <td>['they were playing', 'were playing soccer', '...</td>\n",
              "      <td>[-9.9777804e-05 -2.6923325e-04 -1.0527767e-03 ...</td>\n",
              "      <td>[-0.00390252  0.00116026  0.00490098 -0.003110...</td>\n",
              "      <td>[ 3.8320364e-03 -9.6556135e-03 -1.7034016e-03 ...</td>\n",
              "      <td>[ 0.00012496 -0.00871335 -0.00053851 -0.003852...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>verb tense errors</td>\n",
              "      <td>she have completed her homework</td>\n",
              "      <td>she has completed her homework</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>['she', 'have', 'completed', 'her', 'homework']</td>\n",
              "      <td>['she', 'has', 'completed', 'her', 'homework']</td>\n",
              "      <td>[('she', 'PRP'), ('have', 'VBP'), ('completed'...</td>\n",
              "      <td>[('she', 'PRP'), ('has', 'VBZ'), ('completed',...</td>\n",
              "      <td>[-0.16420007 -0.03099914 -0.17860003 -0.127690...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-2.67656505e-01  3.97760749e-01  1.48411125e-...</td>\n",
              "      <td>[-0.28929004  0.39424703  0.13514736  0.038457...</td>\n",
              "      <td>['she have', 'have completed', 'completed her'...</td>\n",
              "      <td>['she has', 'has completed', 'completed her', ...</td>\n",
              "      <td>['she have completed', 'have completed her', '...</td>\n",
              "      <td>['she has completed', 'has completed her', 'co...</td>\n",
              "      <td>[-0.01038111 -0.00510946  0.00610128 -0.000997...</td>\n",
              "      <td>[-0.01103961 -0.00731192 -0.00655014  0.003719...</td>\n",
              "      <td>[ 0.00674664  0.00827969 -0.00871949 -0.008137...</td>\n",
              "      <td>[-4.41420777e-03 -4.46065888e-03  1.07493391e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>verb tense errors</td>\n",
              "      <td>he do not know the answer</td>\n",
              "      <td>he does not know the answer</td>\n",
              "      <td>25</td>\n",
              "      <td>27</td>\n",
              "      <td>['he', 'do', 'not', 'know', 'the', 'answer']</td>\n",
              "      <td>['he', 'does', 'not', 'know', 'the', 'answer']</td>\n",
              "      <td>[('he', 'PRP'), ('do', 'VBZ'), ('not', 'RB'), ...</td>\n",
              "      <td>[('he', 'PRP'), ('does', 'VBZ'), ('not', 'RB')...</td>\n",
              "      <td>[-0.20836382 -0.00077939 -0.24012117 -0.141872...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.31522754  0.4564127   0.18422635  0.063359...</td>\n",
              "      <td>[-0.30345047  0.43326005  0.16985984  0.060665...</td>\n",
              "      <td>['he do', 'do not', 'not know', 'know the', 't...</td>\n",
              "      <td>['he does', 'does not', 'not know', 'know the'...</td>\n",
              "      <td>['he do not', 'do not know', 'not know the', '...</td>\n",
              "      <td>['he does not', 'does not know', 'not know the...</td>\n",
              "      <td>[ 0.01418456  0.00413721  0.00204819 -0.014849...</td>\n",
              "      <td>[ 0.01053579 -0.00204841  0.00280879 -0.013587...</td>\n",
              "      <td>[ 0.00571257  0.00300963  0.00256153  0.005161...</td>\n",
              "      <td>[ 7.0049549e-03  1.2993978e-02  2.4182086e-03 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>verb tense errors</td>\n",
              "      <td>the sun rise in the east</td>\n",
              "      <td>the sun rises in the east</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>['the', 'sun', 'rise', 'in', 'the', 'east']</td>\n",
              "      <td>['the', 'sun', 'rises', 'in', 'the', 'east']</td>\n",
              "      <td>[('the', 'DT'), ('sun', 'NN'), ('rise', 'NN'),...</td>\n",
              "      <td>[('the', 'DT'), ('sun', 'NN'), ('rises', 'VBZ'...</td>\n",
              "      <td>[-0.1375149  -0.03588668 -0.17903697  0.039538...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.31895906  0.41791686  0.10688009  0.039075...</td>\n",
              "      <td>[-0.27703145  0.36579168  0.09558997  0.032692...</td>\n",
              "      <td>['the sun', 'sun rise', 'rise in', 'in the', '...</td>\n",
              "      <td>['the sun', 'sun rises', 'rises in', 'in the',...</td>\n",
              "      <td>['the sun rise', 'sun rise in', 'rise in the',...</td>\n",
              "      <td>['the sun rises', 'sun rises in', 'rises in th...</td>\n",
              "      <td>[-0.0153868   0.00375328 -0.00371052 -0.001361...</td>\n",
              "      <td>[-0.02238916  0.00040568 -0.00079983 -0.002559...</td>\n",
              "      <td>[-1.84255862e-03  6.71423273e-03  2.46263226e-...</td>\n",
              "      <td>[ 0.00578913 -0.00646036  0.00200742  0.002319...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f76740a9-1b95-43d8-ab18-1e2080f53c7e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f76740a9-1b95-43d8-ab18-1e2080f53c7e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f76740a9-1b95-43d8-ab18-1e2080f53c7e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-23e46a61-abb5-43cb-b6cd-33bacb5fe585\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23e46a61-abb5-43cb-b6cd-33bacb5fe585')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-23e46a61-abb5-43cb-b6cd-33bacb5fe585 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing dataset columns\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCbX5bKlEIiz",
        "outputId": "4153ee1c-11b9-490a-cb9e-0bb63d01ea44"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Error Type', 'Ungrammatical Statement', 'Standard English',\n",
            "       'Ungrammatical Length', 'Standard Length', 'Tokenized Ungrammatical',\n",
            "       'Tokenized Standard', 'POS_Ungrammatical', 'POS_Standard',\n",
            "       'POS_W2V_Ungram', 'POS_W2V_Standard', 'POS_seq_U', 'POS_seq_S',\n",
            "       'W2V_Ungram', 'W2V_Standard', 'Bigrams_Ungrammatical',\n",
            "       'Bigrams_Standard', 'Trigrams_Ungrammatical', 'Trigrams_Standard',\n",
            "       'W2V_Bigrams_Ungrammatical', 'W2V_Bigrams_Standard',\n",
            "       'W2V_Trigrams_Ungrammatical', 'W2V_Trigrams_Standard'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "U0lY-Iy8-5Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_experiments = {\n",
        "    'POS':     ('POS_W2V_Ungram',             'POS_W2V_Standard'),\n",
        "    'Unigram': ('W2V_Ungram',                 'W2V_Standard'),\n",
        "    'Bigram':  ('W2V_Bigrams_Ungrammatical',  'W2V_Bigrams_Standard'),\n",
        "    'Trigram': ('W2V_Trigrams_Ungrammatical', 'W2V_Trigrams_Standard')\n",
        "}"
      ],
      "metadata": {
        "id": "3HbXn83odlGJ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure save directory exists\n",
        "save_dir = \"saved_models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Define & apply parser once\n",
        "def parse_embedding(s):\n",
        "    if isinstance(s, str):\n",
        "        return np.array([float(x) for x in s.strip('[]').split()], dtype=float)\n",
        "    return np.zeros(0, dtype=float)\n",
        "\n",
        "for ug_col, st_col in embedding_experiments.values():\n",
        "    df[ug_col] = df[ug_col].apply(parse_embedding)\n",
        "    df[st_col] = df[st_col].apply(parse_embedding)\n",
        "\n",
        "# Helper to stack feature arrays\n",
        "def stack_feats(X):\n",
        "    return np.vstack(X['feat'])\n",
        "\n",
        "# Pipeline builder for Naive Bayes\n",
        "def make_embedding_pipeline_nb(ug_col, st_col):\n",
        "    n = len(df)\n",
        "    feats = list(df[ug_col]) + list(df[st_col])\n",
        "    y     = np.array([0]*n + [1]*n)  # 0=ungrammatical, 1=correct\n",
        "    X_df  = pd.DataFrame({'feat': feats})\n",
        "\n",
        "    stacker = FunctionTransformer(stack_feats, validate=False)\n",
        "    pipe    = Pipeline([\n",
        "        ('stack', stacker),\n",
        "        ('clf',   GaussianNB() )\n",
        "    ])\n",
        "    return pipe, X_df, y\n",
        "\n",
        "# Train/Test split evaluation (90/10) & save models\n",
        "print(\"=== Train/Test split 90/10 with Naive Bayes ===\")\n",
        "trained_pipelines = {}\n",
        "\n",
        "for name, (ug, st) in embedding_experiments.items():\n",
        "    pipe, X_df, y = make_embedding_pipeline_nb(ug, st)\n",
        "\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X_df, y,\n",
        "        test_size=0.1,\n",
        "        stratify=y,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train & evaluate\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    preds = pipe.predict(X_te)\n",
        "    trained_pipelines[name] = pipe\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"\\n{name} accuracy: {accuracy_score(y_te, preds):.4f}\")\n",
        "    print(classification_report(y_te, preds, digits=4))\n",
        "\n",
        "    # Save trained pipeline\n",
        "    model_path = os.path.join(save_dir, f\"{name}_nb_pipeline.pkl\")\n",
        "    joblib.dump(pipe, model_path)\n",
        "    print(f\"Saved model to {model_path}\")\n"
      ],
      "metadata": {
        "id": "OVtjWi1pgB3-",
        "outputId": "09b8abe7-17f8-4e6a-9dc2-5c3667aa43f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train/Test split 90/10 with Naive Bayes ===\n",
            "\n",
            "POS accuracy: 0.5545\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5663    0.4653    0.5109       202\n",
            "           1     0.5462    0.6436    0.5909       202\n",
            "\n",
            "    accuracy                         0.5545       404\n",
            "   macro avg     0.5562    0.5545    0.5509       404\n",
            "weighted avg     0.5562    0.5545    0.5509       404\n",
            "\n",
            "Saved model to saved_models/POS_nb_pipeline.pkl\n",
            "\n",
            "Unigram accuracy: 0.5074\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5062    0.6089    0.5528       202\n",
            "           1     0.5093    0.4059    0.4518       202\n",
            "\n",
            "    accuracy                         0.5074       404\n",
            "   macro avg     0.5077    0.5074    0.5023       404\n",
            "weighted avg     0.5077    0.5074    0.5023       404\n",
            "\n",
            "Saved model to saved_models/Unigram_nb_pipeline.pkl\n",
            "\n",
            "Bigram accuracy: 0.4926\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4946    0.6782    0.5720       202\n",
            "           1     0.4882    0.3069    0.3769       202\n",
            "\n",
            "    accuracy                         0.4926       404\n",
            "   macro avg     0.4914    0.4926    0.4745       404\n",
            "weighted avg     0.4914    0.4926    0.4745       404\n",
            "\n",
            "Saved model to saved_models/Bigram_nb_pipeline.pkl\n",
            "\n",
            "Trigram accuracy: 0.4802\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4828    0.5545    0.5161       202\n",
            "           1     0.4767    0.4059    0.4385       202\n",
            "\n",
            "    accuracy                         0.4802       404\n",
            "   macro avg     0.4798    0.4802    0.4773       404\n",
            "weighted avg     0.4798    0.4802    0.4773       404\n",
            "\n",
            "Saved model to saved_models/Trigram_nb_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure save directory exists\n",
        "save_dir = \"saved_models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "print(\"\\n=== 10-Fold Cross Validation with Naive Bayes ===\")\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "for name, (ug, st) in embedding_experiments.items():\n",
        "    # Build pipeline and data\n",
        "    pipe, X_df, y = make_embedding_pipeline_nb(ug, st)\n",
        "    accs, precs, recs, f1s = [], [], [], []\n",
        "\n",
        "    # Perform 10-fold CV\n",
        "    for train_idx, test_idx in cv.split(X_df, y):\n",
        "        p = clone(pipe)\n",
        "        X_train, X_test = X_df.iloc[train_idx], X_df.iloc[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        p.fit(X_train, y_train)\n",
        "        preds = p.predict(X_test)\n",
        "\n",
        "        accs.append(accuracy_score(y_test, preds))\n",
        "        precs.append(precision_score(y_test, preds))\n",
        "        recs.append(recall_score(y_test, preds))\n",
        "        f1s.append(f1_score(y_test, preds))\n",
        "\n",
        "    # Calculate mean ± std for each metric\n",
        "    mean_acc, std_acc = np.mean(accs), np.std(accs)\n",
        "    mean_prec, std_prec = np.mean(precs), np.std(precs)\n",
        "    mean_rec, std_rec = np.mean(recs), np.std(recs)\n",
        "    mean_f1, std_f1 = np.mean(f1s), np.std(f1s)\n",
        "\n",
        "    # Print summary\n",
        "    print(\n",
        "        f\"{name} - CV Accuracy: {mean_acc:.4f} ± {std_acc:.4f} | \"\n",
        "        f\"Precision: {mean_prec:.4f} ± {std_prec:.4f} | \"\n",
        "        f\"Recall: {mean_rec:.4f} ± {std_rec:.4f} | \"\n",
        "        f\"F1: {mean_f1:.4f} ± {std_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Retrain on full dataset and save final model\n",
        "    pipe.fit(X_df, y)\n",
        "    model_path = os.path.join(save_dir, f\"{name}_CV_nb_pipeline.pkl\")\n",
        "    joblib.dump(pipe, model_path)\n",
        "    print(f\"Saved final CV model to {model_path}\")"
      ],
      "metadata": {
        "id": "nbbLRbclrnSn",
        "outputId": "519f92e1-12ae-4137-dfc0-22289aba3d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 10-Fold Cross Validation with Naive Bayes ===\n",
            "POS - CV Accuracy: 0.5223 ± 0.0200 | Precision: 0.5184 ± 0.0161 | Recall: 0.6318 ± 0.0265 | F1: 0.5693 ± 0.0184\n",
            "Saved final CV model to saved_models/POS_CV_nb_pipeline.pkl\n",
            "Unigram - CV Accuracy: 0.5141 ± 0.0264 | Precision: 0.5174 ± 0.0335 | Recall: 0.4535 ± 0.0440 | F1: 0.4820 ± 0.0309\n",
            "Saved final CV model to saved_models/Unigram_CV_nb_pipeline.pkl\n",
            "Bigram - CV Accuracy: 0.5027 ± 0.0166 | Precision: 0.5040 ± 0.0273 | Recall: 0.2993 ± 0.0364 | F1: 0.3748 ± 0.0338\n",
            "Saved final CV model to saved_models/Bigram_CV_nb_pipeline.pkl\n",
            "Trigram - CV Accuracy: 0.5064 ± 0.0209 | Precision: 0.5077 ± 0.0274 | Recall: 0.4083 ± 0.0394 | F1: 0.4520 ± 0.0324\n",
            "Saved final CV model to saved_models/Trigram_CV_nb_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where models are saved\n",
        "save_dir = \"saved_models\"\n",
        "\n",
        "# Reload all Naive Bayes models into a new dictionary\n",
        "loaded_pipelines = {}\n",
        "\n",
        "for name in embedding_experiments.keys():\n",
        "    model_variants = {}\n",
        "\n",
        "    # Load train/test split NB model\n",
        "    path_train = os.path.join(save_dir, f\"{name}_nb_pipeline.pkl\")\n",
        "    if os.path.exists(path_train):\n",
        "        model_variants['train'] = joblib.load(path_train)\n",
        "        print(f\"Loaded trained NB model: {name}\")\n",
        "\n",
        "    # Load final CV NB model\n",
        "    path_cv = os.path.join(save_dir, f\"{name}_CV_nb_pipeline.pkl\")\n",
        "    if os.path.exists(path_cv):\n",
        "        model_variants['cv'] = joblib.load(path_cv)\n",
        "        print(f\"Loaded CV NB model: {name}\")\n",
        "\n",
        "    if model_variants:\n",
        "        loaded_pipelines[name] = model_variants\n"
      ],
      "metadata": {
        "id": "tqboL1QOyp6F",
        "outputId": "5c92d114-67be-4cfb-95c6-03f7a9b8f603",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded trained NB model: POS\n",
            "Loaded CV NB model: POS\n",
            "Loaded trained NB model: Unigram\n",
            "Loaded CV NB model: Unigram\n",
            "Loaded trained NB model: Bigram\n",
            "Loaded CV NB model: Bigram\n",
            "Loaded trained NB model: Trigram\n",
            "Loaded CV NB model: Trigram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved Naive Bayes pipelines\n",
        "save_dir = \"saved_models\"\n",
        "model_names = [\"POS\", \"Unigram\", \"Bigram\", \"Trigram\"]\n",
        "\n",
        "# Stub feature-extractor functions\n",
        "def get_pos_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "\n",
        "def get_unigram_features(sentence):\n",
        "    return np.random.rand(100)\n",
        "\n",
        "def get_bigram_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "\n",
        "def get_trigram_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "\n",
        "def extract_features_for_models(sentence):\n",
        "    return {\n",
        "        'POS':     get_pos_features(sentence),\n",
        "        'Unigram': get_unigram_features(sentence),\n",
        "        'Bigram':  get_bigram_features(sentence),\n",
        "        'Trigram': get_trigram_features(sentence)\n",
        "    }\n",
        "\n",
        "# Prediction function\n",
        "def predict_sentence(sentence, pipelines):\n",
        "    feats = extract_features_for_models(sentence)\n",
        "    print(f\"\\nInput sentence: {sentence}\\n\")\n",
        "    for name, variants in pipelines.items():\n",
        "        arr = pd.DataFrame({'feat': [feats[name]]})\n",
        "        if 'train' in variants:\n",
        "            pred = variants['train'].predict(arr)[0]\n",
        "            prob = variants['train'].predict_proba(arr)[0][1]\n",
        "            label = \"Correct\" if pred == 1 else \"Incorrect\"\n",
        "            print(f\"{name} (train): {label} (confidence: {prob:.2f})\")\n",
        "        if 'cv' in variants:\n",
        "            pred = variants['cv'].predict(arr)[0]\n",
        "            prob = variants['cv'].predict_proba(arr)[0][1]\n",
        "            label = \"Correct\" if pred == 1 else \"Incorrect\"\n",
        "            print(f\"{name} (CV):    {label} (confidence: {prob:.2f})\")\n",
        "\n",
        "# Run interactive prompt\n",
        "if __name__ == \"__main__\":\n",
        "    sentence = input(\"Enter a sentence to check: \")\n",
        "    predict_sentence(sentence, loaded_pipelines)"
      ],
      "metadata": {
        "id": "9fu9d__czP4w",
        "outputId": "fb7422c5-3486-4daf-9127-67fbd76509e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to check: she are running now\n",
            "\n",
            "Input sentence: she are running now\n",
            "\n",
            "POS (train): Incorrect (confidence: 0.00)\n",
            "POS (CV):    Incorrect (confidence: 0.00)\n",
            "Unigram (train): Correct (confidence: 1.00)\n",
            "Unigram (CV):    Incorrect (confidence: 0.00)\n",
            "Bigram (train): Correct (confidence: 1.00)\n",
            "Bigram (CV):    Correct (confidence: 1.00)\n",
            "Trigram (train): Correct (confidence: 1.00)\n",
            "Trigram (CV):    Correct (confidence: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "MB3MkbMnrIso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Make directory to save models\n",
        "save_dir = \"saved_models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "def stack_feats(X):\n",
        "    return np.vstack(X['feat'])\n",
        "\n",
        "def make_embedding_pipeline_svm(ug_col, st_col):\n",
        "    n = len(df)\n",
        "    feats = list(df[ug_col]) + list(df[st_col])\n",
        "    y     = np.array([0]*n + [1]*n)  # 0=ungrammatical, 1=correct\n",
        "    X_df  = pd.DataFrame({'feat': feats})\n",
        "    stacker = FunctionTransformer(stack_feats, validate=False)\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        ('stack', stacker),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf',   SVC(kernel='linear',class_weight='balanced',probability=True))\n",
        "    ])\n",
        "    return pipe, X_df, y\n",
        "\n",
        "trained_pipelines = {}\n",
        "print(\"=== Train/Test split 90/10 with SVM ===\")\n",
        "for name, (ug, st) in embedding_experiments.items():\n",
        "    pipe, X_df, y = make_embedding_pipeline_svm(ug, st)\n",
        "\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X_df, y,\n",
        "        test_size=0.1,\n",
        "        stratify=y,\n",
        "        random_state=42\n",
        "    )\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    preds = pipe.predict(X_te)\n",
        "    trained_pipelines[name] = pipe\n",
        "\n",
        "    print(f\"\\n{name} accuracy: {accuracy_score(y_te, preds):.4f}\")\n",
        "    print(classification_report(y_te, preds, digits=4))\n",
        "\n",
        "    # Save model\n",
        "    model_path = os.path.join(save_dir, f\"{name}_svm_pipeline.pkl\")\n",
        "    joblib.dump(pipe, model_path)\n",
        "    print(f\"Saved model to {model_path}\")"
      ],
      "metadata": {
        "id": "LBirOwWtrIKD",
        "outputId": "54360c08-b067-498e-e1ac-5fd6627bf34b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train/Test split 90/10 with SVM ===\n",
            "\n",
            "POS accuracy: 0.5495\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5549    0.5000    0.5260       202\n",
            "           1     0.5450    0.5990    0.5708       202\n",
            "\n",
            "    accuracy                         0.5495       404\n",
            "   macro avg     0.5500    0.5495    0.5484       404\n",
            "weighted avg     0.5500    0.5495    0.5484       404\n",
            "\n",
            "Saved model to saved_models/POS_svm_pipeline.pkl\n",
            "\n",
            "Unigram accuracy: 0.5470\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5450    0.5693    0.5569       202\n",
            "           1     0.5492    0.5248    0.5367       202\n",
            "\n",
            "    accuracy                         0.5470       404\n",
            "   macro avg     0.5471    0.5470    0.5468       404\n",
            "weighted avg     0.5471    0.5470    0.5468       404\n",
            "\n",
            "Saved model to saved_models/Unigram_svm_pipeline.pkl\n",
            "\n",
            "Bigram accuracy: 0.4827\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4817    0.4554    0.4682       202\n",
            "           1     0.4836    0.5099    0.4964       202\n",
            "\n",
            "    accuracy                         0.4827       404\n",
            "   macro avg     0.4826    0.4827    0.4823       404\n",
            "weighted avg     0.4826    0.4827    0.4823       404\n",
            "\n",
            "Saved model to saved_models/Bigram_svm_pipeline.pkl\n",
            "\n",
            "Trigram accuracy: 0.5149\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5146    0.5248    0.5196       202\n",
            "           1     0.5152    0.5050    0.5100       202\n",
            "\n",
            "    accuracy                         0.5149       404\n",
            "   macro avg     0.5149    0.5149    0.5148       404\n",
            "weighted avg     0.5149    0.5149    0.5148       404\n",
            "\n",
            "Saved model to saved_models/Trigram_svm_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== 10-Fold Cross Validation with SVM  ===\")\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "cv_results = {}\n",
        "\n",
        "for name, (ug, st) in embedding_experiments.items():\n",
        "    # Prepare input features and labels\n",
        "    pipe, X_df, y = make_embedding_pipeline_svm(ug, st)\n",
        "\n",
        "    fold_precisions = []\n",
        "    fold_recalls = []\n",
        "    fold_f1s = []\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "    fold_accuracies = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_df, y)):\n",
        "        X_train, X_val = X_df.iloc[train_idx], X_df.iloc[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        fold_model = Pipeline([\n",
        "            ('stack', FunctionTransformer(stack_feats, validate=False)),\n",
        "            ('clf', SVC(kernel='linear', class_weight='balanced', probability=True))\n",
        "        ])\n",
        "        fold_model.fit(X_train, y_train)\n",
        "        preds = fold_model.predict(X_val)\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_true.extend(y_val)\n",
        "\n",
        "        # Metrics per fold\n",
        "        acc = accuracy_score(y_val, preds)\n",
        "        prec = precision_score(y_val, preds, average='binary', zero_division=0)\n",
        "        rec = recall_score(y_val, preds, average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_val, preds, average='binary', zero_division=0)\n",
        "\n",
        "        fold_accuracies.append(acc)\n",
        "        fold_precisions.append(prec)\n",
        "        fold_recalls.append(rec)\n",
        "        fold_f1s.append(f1)\n",
        "\n",
        "    # Mean and Std for each metric\n",
        "    mean_acc, std_acc = np.mean(fold_accuracies), np.std(fold_accuracies)\n",
        "    mean_prec, std_prec = np.mean(fold_precisions), np.std(fold_precisions)\n",
        "    mean_rec, std_rec = np.mean(fold_recalls), np.std(fold_recalls)\n",
        "    mean_f1, std_f1 = np.mean(fold_f1s), np.std(fold_f1s)\n",
        "\n",
        "    # Print summary in desired format\n",
        "    print(f\"{name} - CV Accuracy: {mean_acc:.4f} ± {std_acc:.4f} | \"\n",
        "          f\"Precision: {mean_prec:.4f} ± {std_prec:.4f} | \"\n",
        "          f\"Recall: {mean_rec:.4f} ± {std_rec:.4f} | \"\n",
        "          f\"F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
        "\n",
        "    # Save the final model trained on the entire dataset\n",
        "    pipe.fit(X_df, y)\n",
        "    model_path = os.path.join(save_dir, f\"{name}_CV_svm_pipeline.pkl\")\n",
        "    joblib.dump(pipe, model_path)\n",
        "    print(f\"Saved final CV model to {model_path}\")"
      ],
      "metadata": {
        "id": "U4lFP1Kpm1uK",
        "outputId": "ad59f644-def9-4bd9-d1bb-1f95180e1a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 10-Fold Cross Validation with SVM  ===\n",
            "POS - CV Accuracy: 0.5317 ± 0.0172 | Precision: 0.5286 ± 0.0153 | Recall: 0.5887 ± 0.0249 | F1: 0.5568 ± 0.0169\n",
            "Saved final CV model to saved_models/POS_CV_svm_pipeline.pkl\n",
            "Unigram - CV Accuracy: 0.5188 ± 0.0281 | Precision: 0.5180 ± 0.0266 | Recall: 0.5516 ± 0.0437 | F1: 0.5336 ± 0.0298\n",
            "Saved final CV model to saved_models/Unigram_CV_svm_pipeline.pkl\n",
            "Bigram - CV Accuracy: 0.5069 ± 0.0173 | Precision: 0.4045 ± 0.2043 | Recall: 0.3837 ± 0.4234 | F1: 0.3024 ± 0.2913\n",
            "Saved final CV model to saved_models/Bigram_CV_svm_pipeline.pkl\n",
            "Trigram - CV Accuracy: 0.4936 ± 0.0090 | Precision: 0.3561 ± 0.1898 | Recall: 0.3064 ± 0.3814 | F1: 0.2587 ± 0.2596\n",
            "Saved final CV model to saved_models/Trigram_CV_svm_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload all models into a new dictionary\n",
        "loaded_pipelines = {}\n",
        "for name in embedding_experiments.keys():\n",
        "    model_variants = {}\n",
        "    # Load train/test split model\n",
        "    path_train = os.path.join(save_dir, f\"{name}_svm_pipeline.pkl\")\n",
        "    if os.path.exists(path_train):\n",
        "        model_variants['train'] = joblib.load(path_train)\n",
        "        print(f\"Loaded trained model: {name}\")\n",
        "\n",
        "    # Load final CV model\n",
        "    path_cv = os.path.join(save_dir, f\"{name}_CV_svm_pipeline.pkl\")\n",
        "    if os.path.exists(path_cv):\n",
        "        model_variants['cv'] = joblib.load(path_cv)\n",
        "        print(f\"Loaded CV model: {name}\")\n",
        "\n",
        "    # Optional: use loaded_pipelines as default in your prediction functions\n",
        "    loaded_pipelines[name] = model_variants\n"
      ],
      "metadata": {
        "id": "ZgETHs84aFtW",
        "outputId": "47c351b8-d125-48f9-a353-c6e9d4a2f167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded trained model: POS\n",
            "Loaded CV model: POS\n",
            "Loaded trained model: Unigram\n",
            "Loaded CV model: Unigram\n",
            "Loaded trained model: Bigram\n",
            "Loaded CV model: Bigram\n",
            "Loaded trained model: Trigram\n",
            "Loaded CV model: Trigram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "\n",
        "def get_unigram_features(sentence):\n",
        "    return np.random.rand(100)\n",
        "\n",
        "def get_bigram_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "\n",
        "def get_trigram_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "\n",
        "def extract_features_for_models(sentence):\n",
        "    features = {}\n",
        "\n",
        "    features['POS'] = get_pos_features(sentence)\n",
        "    features['Unigram'] = get_unigram_features(sentence)\n",
        "    features['Bigram'] = get_bigram_features(sentence)\n",
        "    features['Trigram'] = get_trigram_features(sentence)\n",
        "\n",
        "    return features\n",
        "\n",
        "def predict_sentence(sentence, pipelines):\n",
        "    feats_dict = extract_features_for_models(sentence)\n",
        "    print(f\"Input sentence: {sentence}\\n\")\n",
        "\n",
        "    for model_name, model_variants in pipelines.items():\n",
        "        X_test_df = pd.DataFrame({'feat': [feats_dict[model_name]]})\n",
        "\n",
        "        # Predict using train/test model\n",
        "        if 'train' in model_variants:\n",
        "            pred = model_variants['train'].predict(X_test_df)[0]\n",
        "            prob = model_variants['train'].predict_proba(X_test_df)[0][1]\n",
        "            print(f\"{model_name} (train): {'Correct' if pred == 1 else 'Incorrect'} (confidence: {prob:.2f})\")\n",
        "\n",
        "        # Predict using CV model\n",
        "        if 'cv' in model_variants:\n",
        "            pred = model_variants['cv'].predict(X_test_df)[0]\n",
        "            prob = model_variants['cv'].predict_proba(X_test_df)[0][1]\n",
        "            print(f\"{model_name} (CV): {'Correct' if pred == 1 else 'Incorrect'} (confidence: {prob:.2f})\")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "sentence = input(\"Enter a sentence to check: \")\n",
        "predict_sentence(sentence, loaded_pipelines)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12lRWWeBF652",
        "outputId": "ce8b453e-670b-48a3-f304-6ec4301b7a04"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to check: she are running now\n",
            "Input sentence: she are running now\n",
            "\n",
            "POS (train): Correct (confidence: 1.00)\n",
            "POS (CV): Correct (confidence: 1.00)\n",
            "Unigram (train): Incorrect (confidence: 0.47)\n",
            "Unigram (CV): Incorrect (confidence: 0.00)\n",
            "Bigram (train): Incorrect (confidence: 0.47)\n",
            "Bigram (CV): Incorrect (confidence: 0.93)\n",
            "Trigram (train): Incorrect (confidence: 0.78)\n",
            "Trigram (CV): Incorrect (confidence: 0.54)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "jHMl87xFKZd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Configuration\n",
        "save_dir = \"saved_models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# 0) Parse embeddings (handle both strings and arrays)\n",
        "def parse_embedding(s):\n",
        "    if isinstance(s, str):\n",
        "        return np.array([float(x) for x in s.strip(\"[]\").split()], dtype=float)\n",
        "    elif isinstance(s, (list, np.ndarray)):\n",
        "        return np.array(s, dtype=float)\n",
        "    else:\n",
        "        return np.zeros(0, dtype=float)\n",
        "\n",
        "for ug_col, st_col in embedding_experiments.values():\n",
        "    df[ug_col] = df[ug_col].apply(parse_embedding)\n",
        "    df[st_col] = df[st_col].apply(parse_embedding)\n",
        "\n",
        "# Helper to stack feature arrays\n",
        "def stack_feats(X):\n",
        "    return np.vstack(X[\"feat\"])\n",
        "\n",
        "# Pipeline builder for XGBoost\n",
        "def make_embedding_pipeline_xgb(ug_col, st_col):\n",
        "    n     = len(df)\n",
        "    feats = list(df[ug_col]) + list(df[st_col])\n",
        "    y     = np.array([0]*n + [1]*n)\n",
        "    X_df  = pd.DataFrame({\"feat\": feats})\n",
        "\n",
        "    stacker = FunctionTransformer(stack_feats, validate=False)\n",
        "    pipe    = Pipeline([\n",
        "        (\"stack\", stacker),\n",
        "        (\"clf\",   XGBClassifier(eval_metric=\"logloss\", random_state=42))\n",
        "    ])\n",
        "    return pipe, X_df, y\n",
        "\n",
        "# 2) 90/10 Train/Test Split\n",
        "print(\"=== Train/Test split 90/10 with XGBoost ===\")\n",
        "for name, (ug, st) in embedding_experiments.items():\n",
        "    pipe, X_df, y = make_embedding_pipeline_xgb(ug, st)\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X_df, y, test_size=0.1, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    preds = pipe.predict(X_te)\n",
        "\n",
        "    print(f\"\\n{name} accuracy: {accuracy_score(y_te, preds):.4f}\")\n",
        "    print(classification_report(y_te, preds, digits=4))\n",
        "\n",
        "    # Save the pipeline\n",
        "    model_path = os.path.join(save_dir, f\"{name}_xgb_pipeline.pkl\")\n",
        "    joblib.dump(pipe, model_path)\n",
        "    print(f\"Saved XGBoost pipeline to {model_path}\")\n"
      ],
      "metadata": {
        "id": "nuYmjkw3KZKe",
        "outputId": "3eef94a0-7d3c-40df-fb2a-1a6dd2a48496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train/Test split 90/10 with XGBoost ===\n",
            "\n",
            "POS accuracy: 0.4827\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4834    0.5050    0.4939       202\n",
            "           1     0.4819    0.4604    0.4709       202\n",
            "\n",
            "    accuracy                         0.4827       404\n",
            "   macro avg     0.4826    0.4827    0.4824       404\n",
            "weighted avg     0.4826    0.4827    0.4824       404\n",
            "\n",
            "Saved XGBoost pipeline to saved_models/POS_xgb_pipeline.pkl\n",
            "\n",
            "Unigram accuracy: 0.4406\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4400    0.4356    0.4378       202\n",
            "           1     0.4412    0.4455    0.4433       202\n",
            "\n",
            "    accuracy                         0.4406       404\n",
            "   macro avg     0.4406    0.4406    0.4406       404\n",
            "weighted avg     0.4406    0.4406    0.4406       404\n",
            "\n",
            "Saved XGBoost pipeline to saved_models/Unigram_xgb_pipeline.pkl\n",
            "\n",
            "Bigram accuracy: 0.3911\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3911    0.3911    0.3911       202\n",
            "           1     0.3911    0.3911    0.3911       202\n",
            "\n",
            "    accuracy                         0.3911       404\n",
            "   macro avg     0.3911    0.3911    0.3911       404\n",
            "weighted avg     0.3911    0.3911    0.3911       404\n",
            "\n",
            "Saved XGBoost pipeline to saved_models/Bigram_xgb_pipeline.pkl\n",
            "\n",
            "Trigram accuracy: 0.4381\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4396    0.4505    0.4450       202\n",
            "           1     0.4365    0.4257    0.4311       202\n",
            "\n",
            "    accuracy                         0.4381       404\n",
            "   macro avg     0.4381    0.4381    0.4380       404\n",
            "weighted avg     0.4381    0.4381    0.4380       404\n",
            "\n",
            "Saved XGBoost pipeline to saved_models/Trigram_xgb_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "# 10-fold stratified CV splitter\n",
        "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    \"clf__n_estimators\":  [50, 100, 200],\n",
        "    \"clf__max_depth\":     [3, 4, 5],\n",
        "    \"clf__learning_rate\": [0.01, 0.05, 0.1]\n",
        "}\n",
        "\n",
        "print(\"\\n=== 10-Fold Grid Search CV for XGBoost ===\")\n",
        "for name, (ug, st) in embedding_experiments.items():\n",
        "    # rebuild the pipeline and data\n",
        "    pipe, X_df, y = make_embedding_pipeline_xgb(ug, st)\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        estimator=pipe,\n",
        "        param_grid=param_grid,\n",
        "        cv=cv_outer,\n",
        "        scoring=\"accuracy\",\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "    grid.fit(X_df, y)\n",
        "\n",
        "    # report\n",
        "    print(f\"\\n{name} best params: {grid.best_params_}\")\n",
        "    print(f\"{name} best CV accuracy: {grid.best_score_:.4f}\")\n",
        "\n",
        "    # save the tuned pipeline\n",
        "    best_path = os.path.join(save_dir, f\"{name}_xgb_grid_pipeline.pkl\")\n",
        "    joblib.dump(grid.best_estimator_, best_path)\n",
        "    print(f\"Saved best XGBoost pipeline to {best_path}\")"
      ],
      "metadata": {
        "id": "v67U1A3aRk7s",
        "outputId": "3a49a41b-7047-4b3b-ed9e-d76b20fe53aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 10-Fold Grid Search CV for XGBoost ===\n",
            "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
            "\n",
            "POS best params: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 50}\n",
            "POS best CV accuracy: 0.5339\n",
            "Saved best XGBoost pipeline to saved_models/POS_xgb_grid_pipeline.pkl\n",
            "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
            "\n",
            "Unigram best params: {'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 100}\n",
            "Unigram best CV accuracy: 0.5300\n",
            "Saved best XGBoost pipeline to saved_models/Unigram_xgb_grid_pipeline.pkl\n",
            "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
            "\n",
            "Bigram best params: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 50}\n",
            "Bigram best CV accuracy: 0.4950\n",
            "Saved best XGBoost pipeline to saved_models/Bigram_xgb_grid_pipeline.pkl\n",
            "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
            "\n",
            "Trigram best params: {'clf__learning_rate': 0.01, 'clf__max_depth': 4, 'clf__n_estimators': 50}\n",
            "Trigram best CV accuracy: 0.4888\n",
            "Saved best XGBoost pipeline to saved_models/Trigram_xgb_grid_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload saved XGBoost pipelines\n",
        "save_dir = \"saved_models\"\n",
        "loaded_xgb = {}\n",
        "for name in embedding_experiments.keys():\n",
        "    variants = {}\n",
        "    p_train = os.path.join(save_dir, f\"{name}_xgb_pipeline.pkl\")\n",
        "    p_grid  = os.path.join(save_dir, f\"{name}_xgb_grid_pipeline.pkl\")\n",
        "    if os.path.exists(p_train):\n",
        "        variants['train'] = joblib.load(p_train)\n",
        "        print(f\"Loaded XGB train model: {name}\")\n",
        "    if os.path.exists(p_grid):\n",
        "        variants['grid']  = joblib.load(p_grid)\n",
        "        print(f\"Loaded XGB grid-model: {name}\")\n",
        "    if variants:\n",
        "        loaded_xgb[name] = variants"
      ],
      "metadata": {
        "id": "x4sorh3gX2EC",
        "outputId": "ae2a48ef-61ee-4b64-930d-f9c8f1432acf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded XGB train model: POS\n",
            "Loaded XGB grid-model: POS\n",
            "Loaded XGB train model: Unigram\n",
            "Loaded XGB grid-model: Unigram\n",
            "Loaded XGB train model: Bigram\n",
            "Loaded XGB grid-model: Bigram\n",
            "Loaded XGB train model: Trigram\n",
            "Loaded XGB grid-model: Trigram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stub feature-extractor functions\n",
        "def get_pos_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "def get_unigram_features(sentence):\n",
        "    return np.random.rand(100)\n",
        "def get_bigram_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "def get_trigram_features(sentence):\n",
        "    return np.random.rand(50)\n",
        "\n",
        "def extract_features_for_models(sentence):\n",
        "    return {\n",
        "        'POS':     get_pos_features(sentence),\n",
        "        'Unigram': get_unigram_features(sentence),\n",
        "        'Bigram':  get_bigram_features(sentence),\n",
        "        'Trigram': get_trigram_features(sentence)\n",
        "    }\n",
        "\n",
        "# Prediction function for XGB only\n",
        "def predict_with_xgb(sentence, xgb_pipelines):\n",
        "    feats = extract_features_for_models(sentence)\n",
        "    print(f\"\\nInput sentence: {sentence}\\n\")\n",
        "    for name, variants in xgb_pipelines.items():\n",
        "        df_feat = pd.DataFrame({'feat': [feats[name]]})\n",
        "        for tag, model in variants.items():\n",
        "            pred = model.predict(df_feat)[0]\n",
        "            prob = model.predict_proba(df_feat)[0][1]\n",
        "            label = \"Correct\" if pred == 1 else \"Incorrect\"\n",
        "            print(f\"{name} XGB ({tag}): {label} (confidence: {prob:.2f})\")\n",
        "\n",
        "# Test on an example\n",
        "sentence = input(\"Enter a sentence to check:\\n> \")\n",
        "predict_with_xgb(sentence, loaded_xgb)"
      ],
      "metadata": {
        "id": "5ZPRzV7QX9aW",
        "outputId": "a7c1fa33-20de-47b0-eb44-3fcd49e3c0db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to check:\n",
            "> she are running now\n",
            "\n",
            "Input sentence: she are running now\n",
            "\n",
            "POS XGB (train): Correct (confidence: 0.65)\n",
            "POS XGB (grid): Incorrect (confidence: 0.34)\n",
            "Unigram XGB (train): Incorrect (confidence: 0.12)\n",
            "Unigram XGB (grid): Incorrect (confidence: 0.38)\n",
            "Bigram XGB (train): Incorrect (confidence: 0.22)\n",
            "Bigram XGB (grid): Incorrect (confidence: 0.35)\n",
            "Trigram XGB (train): Incorrect (confidence: 0.34)\n",
            "Trigram XGB (grid): Correct (confidence: 0.53)\n"
          ]
        }
      ]
    }
  ]
}